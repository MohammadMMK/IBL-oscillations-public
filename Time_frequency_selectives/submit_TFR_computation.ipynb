{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load decoding results\n",
    "beacuse we only want to compute tfr for the specific channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to https://openalyx.internationalbrainlab.org as user \"intbrainlab\"\n",
      "Total number of possible probe insertions: 205\n",
      "Number of sessions without passive data: 76\n",
      "Number of sessions with passive data: 129\n",
      "Number of missing pids: 121\n",
      " number of total channnels 272\n",
      "Right selective:  1\n",
      "Left selective:  6\n",
      "  Region  Right Selective  Left Selective\n",
      "0   VISp                1               6\n",
      "1  VISpm                0               0\n",
      "2  VISam                0               0\n",
      "3   VISa                0               0\n",
      "4  VISrl                0               0\n",
      "5  VISal                0               0\n",
      "6  VISli                0               0\n",
      "7   VISl                0               0\n"
     ]
    }
   ],
   "source": [
    "# import functions\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np  \n",
    "import submitit\n",
    "import os \n",
    "import mne\n",
    "sys.path.append(str(Path(os.getcwd()).resolve().parent)) # add the root of the project to the python path\n",
    "from extraction_data import get_pid_eid_pairs\n",
    "from config import paths\n",
    "from functions import get_TFR, load_decoding_results, selective_channels , preprocess_LFP, split_trials\n",
    "\n",
    "\n",
    "# get the pid and eid of the sessions to analyze\n",
    "regionOfInterest = ['VISp', 'VISpm', 'VISam', 'VISa', 'VISrl', 'VISal', 'VISli', 'VISl'] # regions to include\n",
    "pid_eid_pairs = get_pid_eid_pairs( regions = regionOfInterest,only_passive= True)\n",
    "\n",
    "# get the decoding results\n",
    "decoding_results_dir = os.path.join(str(Path(os.getcwd()).resolve().parent), 'Decoding_spikes', 'results')\n",
    "results = load_decoding_results(pid_eid_pairs, suffix = 'v1_TPassive_TActive' , dir = decoding_results_dir)\n",
    "right_selective, left_selective, right_sensitive, left_sensitive, neutral = selective_channels(results)\n",
    "print('Right selective: ', len(right_selective))\n",
    "print('Left selective: ', len(left_selective))\n",
    "RS_ch = right_selective['acronyms']\n",
    "LS_ch = left_selective['acronyms']\n",
    "\n",
    "# print the number of selective channels per region\n",
    "data = []\n",
    "for region in regionOfInterest:\n",
    "    RS_count = len([ch for ch in RS_ch if re.match(rf'^{region}[12456]', ch)])\n",
    "    LS_count = len([ch for ch in LS_ch if re.match(rf'^{region}[12456]', ch)])\n",
    "    data.append([region, RS_count, LS_count])\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data, columns=['Region', 'Right Selective', 'Left Selective'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define parameters \n",
    "\n",
    "## Preprocessing Parameters\n",
    "-   **`tmin`**: Start time of the epoch in seconds. Default is -0.5.\n",
    "-   **`tmax`**:  End time of the epoch in seconds. Default is 1.\n",
    "-   **`cpus`**:  Number of CPUs to use for filtering. Default is 1.\n",
    "-   **`bandpass_filter`**: List containing low and high frequency for bandpass filter. Default is [None, None].\n",
    "-   **`csd`**: Whether to compute Current Source Density (CSD). Default is False.\n",
    "-   **`bipolar`** Whether to compute bipolar signals. Default is False.\n",
    "\n",
    "\n",
    "\n",
    "## split data into two parts\n",
    "\n",
    "#### 1 BiasRight_BiasLeft_anticip\n",
    "\n",
    "- TFR for left  - right  during anticiaption of the target in left selective electrodes\n",
    "\n",
    "- TFR  right  - left  during anticipation of the target in right selective electrodes\n",
    "  \n",
    "```python\n",
    "condition1_trial = np.where(meta['probabilityLeft'] == 0.2 )[0]\n",
    "condition2_trial = np.where(meta['probabilityLeft'] == 0.8 )[0]\n",
    "```\n",
    "\n",
    "#### 2 BiasLeft_BiasRight_stimLeft\n",
    "\n",
    "- TFR left stimulus present 80 - TFR left stimulus present 20 in left selective electrodes\n",
    "\n",
    "```python\n",
    "condition1_trial = np.where((meta['probabilityLeft'] == 0.8) & (meta['contrastLeft'] > 0.2))[0]\n",
    "condition2_trial = np.where((meta['probabilityLeft'] == 0.2) & (meta['contrastLeft'] > 0.2))[0]\n",
    "```\n",
    "#### 3 BiasLeft_BiasRight_stimRight\n",
    "- TFR right stimulus present 80 - TFR right stimulus present 20 in right selective electrodes\n",
    "  \n",
    "```python\n",
    "condition1_trial = np.where((meta['probabilityLeft'] == 0.8) & (meta['contrastRight'] > 0.2))[0]\n",
    "condition2_trial = np.where((meta['probabilityLeft'] == 0.2) & (meta['contrastRight'] > 0.2))[0]\n",
    "```\n",
    "\n",
    "\n",
    "#### 4 BiasLeft_BiasRight_NoStimLeft\n",
    "- TFR left stimulus absent 80 - TFR left stimulus absent 20 in left selective electrodes\n",
    "```python\n",
    "condition1_trial = np.where((meta['probabilityLeft'] == 0.8) & (~(meta['contrastLeft'] > 0)))[0]\n",
    "condition2_trial = np.where((meta['probabilityLeft'] == 0.2) & (~(meta['contrastLeft'] > 0)))[0]\n",
    "```\n",
    "#### 5 BiasLeft_BiasRight_NoStimRight\n",
    "- TFR right stimulus absent 80 - TFR right stimulus absent 20 in right selective electrodes\n",
    "```python\n",
    "condition1_trial = np.where((meta['probabilityLeft'] == 0.8) & (~(meta['contrastRight'] > 0)))[0]\n",
    "condition2_trial = np.where((meta['probabilityLeft'] == 0.2) & (~(meta['contrastRight'] > 0)))[0]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cpus = 5 # for TFR and also bandpass filter\n",
    "Parameters_preprocessing = { 'tmin': -0.5, 'tmax': 1, 'cpus': cpus, 'bandpass_filter': [None, None],  'csd': False, 'bipolar': True}\n",
    "\n",
    "\n",
    "# parameters two split trials\n",
    "remove_first_trials_of_block = True \n",
    "min_trial = 0\n",
    "# 1  TFR for different conditions (see the conditions detail  in the block below)\n",
    "conditions = 'BiasLeft_BiasRight_NoStimLeft'  \n",
    "selectives = left_selective # pid and channels to include\n",
    "#2\n",
    "# conditions = 'BiasLeft_BiasRight_NoStimRight'  \n",
    "# selectives = right_selective\n",
    "# 3\n",
    "# conditions =  'BiasLeft_BiasRight_stimRight'\n",
    "# selectives = right_selective\n",
    "# 4\n",
    "# conditions = 'BiasLeft_BiasRight_stimLeft'\n",
    "# selectives = left_selective\n",
    "# 5\n",
    "# conditions = 'BiasRight_BiasLeft_anticip' \n",
    "# tmin = -0.7\n",
    "# tmax = 0.1\n",
    "# selectives = pd.concat([right_selective, left_selective])\n",
    "\n",
    "# TFR parameters\n",
    "freqs = np.concatenate([np.arange(1, 10, 1), np.arange(10, 45, 1)])\n",
    "n_cycles = freqs / 2. # increase the denominator to increase the temporal resolution\n",
    "time_bandwidth = 3.5 # lower the time-bandwidth parameter, which reduces the time-length of the tapers to increases temporal resolution\n",
    "overwrite = False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compute TFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def submit_get_TFR(pid, preprocess_params = Parameters_preprocessing,  freqs = freqs, n_cycles = n_cycles, time_bandwidth = time_bandwidth, condition = conditions, selectives = selectives, remove_first_trials_of_block = remove_first_trials_of_block, min_trial = min_trial, overwrite = overwrite, cpus = cpus):\n",
    "    ch_index = selectives.loc[selectives['pid'] == pid, 'ch_indexs'].tolist()\n",
    "    eid = [eid for p, eid in pid_eid_pairs if p == pid][0]\n",
    "    if os.path.exists(f'results/{pid}_{condition}.npy') and not overwrite:\n",
    "        print(f'{pid}_{condition} already done')\n",
    "        return\n",
    "\n",
    "    # preprocess the LFP\n",
    "    epochs_mne = preprocess_LFP(pid, eid,ch_index,  **preprocess_params)\n",
    "\n",
    "    # split trials\n",
    "    epochs_1, epochs_2 = split_trials(epochs_mne, condition , min_trial , remove_first_trials_of_block )\n",
    "\n",
    "    # TFR\n",
    "    averageTFR_1 = mne.time_frequency.tfr_multitaper(epochs_1, freqs=freqs, n_cycles=n_cycles, time_bandwidth=time_bandwidth, return_itc=False, average=True, n_jobs= cpus)\n",
    "    averageTFR_2 = mne.time_frequency.tfr_multitaper(epochs_2, freqs=freqs, n_cycles=n_cycles, time_bandwidth=time_bandwidth, return_itc=False, average=True, n_jobs= cpus)\n",
    "    \n",
    "    pid_TFR = {'TFR_1': averageTFR_1, 'TFR_2': averageTFR_2}\n",
    "    # save the TFR in \n",
    "    save_path = os.path.join('results', f'{pid}_{condition}.npy')\n",
    "    np.save(save_path, pid_TFR)\n",
    "    return \n",
    "\n",
    "\n",
    "\n",
    "# remove the first and last channel because of CSD\n",
    "if Parameters_preprocessing['csd'] == True:\n",
    "    selectives = selectives[~selectives['ch_indexs'].isin([0, 383])]\n",
    "\n",
    "# get the pids that are not already done\n",
    "pids = np.unique(selectives['pid'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parallel computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit jobs\n",
    "executor = submitit.AutoExecutor(folder='logs')\n",
    "executor.update_parameters(slurm_array_parallelism= 30 , mem_gb=20, timeout_min= 120, slurm_partition= 'CPU',  cpus_per_task= cpus)\n",
    "# Submit all jobs using map_array                                                                                              \n",
    "all_jobs = executor.map_array(submit_get_TFR, pids)\n",
    "print('Number of pids submited: ', len(all_jobs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pid in pids:\n",
    "    submit_get_TFR(pid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gitenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
