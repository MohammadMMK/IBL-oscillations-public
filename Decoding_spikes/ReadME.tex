% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  letterpaper,
  DIV=11,
  numbers=noendperiod]{scrartcl}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else  
    % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother

\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{241,243,245}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.40,0.45,0.13}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\ExtensionTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.28,0.35,0.67}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{0.00,0.46,0.62}{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.07,0.07,0.07}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{% scales image to fit in text height/width
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi% select the smaller of both
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox{\pandoc@box}%
  \fi%
}
% Set default figure placement to htbp
\def\fps@figure{htbp}
\makeatother

\KOMAoption{captions}{tableheading}
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother

\usepackage{bookmark}

\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}


\author{}
\date{}

\begin{document}


\section{Decoding spikes}\label{decoding-spikes}

In this project the aim is to classify channels in IBL data as right or
left selective based on their firing rate after visual stimulus.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection{Decoding Framework}\label{decoding-framework}

the decoding procedures implemented in the
\texttt{DecodingFramework\_OnCluster} class, which is used to classify
firing rate based on logistic regression. This class is built to
facilitate the decoding of right vs.~left visual stimuli from firing
rates using data from both passive and active conditions. ; active means
the data is recorded during the behavioral protocol while passive
represent the data recorded during passive stimulation. see

\subsubsection{Key Components}\label{key-components}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Data Initialization} The framework accepts both passive and
  active firing rates for a single channel.

  \begin{itemize}
  \tightlist
  \item
    \texttt{data\_passive} \& \texttt{data\_active}: Arrays of shape
    \texttt{(n\_trials,\ n\_clusters,\ n\_time\_bins)} representing
    firing rates for each channel.
  \item
    \texttt{labels\_passive} \& \texttt{labels\_active}: Labels for each
    trial, indicating the condition. right = 1 left = -1 and no\_stim= 0
  \end{itemize}
\item
  \textbf{Feature Selection} Feature selection can be applied using one
  of the following methods:

  \begin{itemize}
  \tightlist
  \item
    \textbf{PCA}: Principal Component Analysis to reduce dimensionality
    by combining cluster and time bin information.
    \texttt{reduced\_data\ =\ (n\_trials,\ n\_components\_of(n\_clusters\ *\ n\_time\_bins))}
  \item
    \textbf{Average Clusters}: Averaging the neural activity over
    clusters to reduce complexity.
  \end{itemize}
\item
  \textbf{Decoding and Cross-Validation} The decoding step uses
  \textbf{Logistic Regression} with an \texttt{L1} penalty, balanced
  class weights, and maximum iterations set to 1000.

  \begin{itemize}
  \tightlist
  \item
    \textbf{Cross-Validation}: A Stratified K-Fold cross-validation
    (\texttt{StratifiedKFold}) is used for test strategy
    \texttt{\textquotesingle{}passive\textquotesingle{}} to validate the
    model.
  \item
    Training and testing datasets are chosen based on the
    \texttt{test\_strategy}:

    \begin{itemize}
    \tightlist
    \item
      \texttt{\textquotesingle{}passive\textquotesingle{}}: Train and
      test using passive data with cross-validation.
    \item
      \texttt{\textquotesingle{}active\textquotesingle{}}: Train on
      passive data and test on active data.
    \item
      \texttt{\textquotesingle{}both\textquotesingle{}}: Train on part
      of the passive data, and test on the rest along with the active
      data.
    \end{itemize}
  \end{itemize}
\item
  \textbf{Null Distribution and Statistical Validation} To validate the
  decoding accuracy, a \textbf{null distribution} is generated using
  label permutation with \texttt{n\_permutations} iterations.

  \begin{itemize}
  \tightlist
  \item
    \textbf{Null Distribution}: Accuracy scores computed after random
    shuffling of labels, repeated across specified permutations.
  \item
    \textbf{p-Value Calculation}: p-values are computed to assess
    statistical significance by comparing true accuracy to the null
    distribution.
  \end{itemize}
\end{enumerate}

\subsubsection{Summary of the Workflow}\label{summary-of-the-workflow}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Data Preparation}: Mask trials to separate right vs.~no
  stimulus and left vs.~no stimulus for passive and active conditions.
\item
  \textbf{Feature Selection}: Apply PCA or average clusters to reduce
  the dimensionality of the dataset.
\item
  \textbf{Model Training and Testing}:

  \begin{itemize}
  \tightlist
  \item
    Train a logistic regression model on the prepared dataset.
  \item
    Apply cross-validation for test strategy
    \texttt{\textquotesingle{}passive\textquotesingle{}}, or train/test
    on different data splits for other strategies.
  \end{itemize}
\item
  \textbf{Validation}: Generate null distributions and calculate
  p-values to verify the statistical significance of the model's
  performance.
\end{enumerate}

\subsubsection{Key Parameters}\label{key-parameters}

\begin{itemize}
\tightlist
\item
  \texttt{n\_folds}: Number of folds for cross-validation.
\item
  \texttt{n\_components}: Number of components to retain for PCA.
\item
  \texttt{n\_permutations}: Number of permutations used for null
  distribution generation.
\item
  \texttt{test\_strategy}: Determines how passive and active datasets
  are used for training and testing.
\end{itemize}

\subsubsection{Results}\label{results}

The final output of the \texttt{decode} method includes:

\begin{itemize}
\tightlist
\item
  \textbf{True Accuracies} (\texttt{true\_accuracy\_right},
  \texttt{true\_accuracy\_left})
\item
  \textbf{Null Distributions} (\texttt{null\_distribution\_right},
  \texttt{null\_distribution\_left})
\item
  \textbf{p-Values} (\texttt{p\_value\_right}, \texttt{p\_value\_left})
\end{itemize}

These results provide insights into the model's performance for both
right and left visual stimuli, and the significance of the observed
accuracies compared to random label shuffling.

\subsubsection{Usage}\label{usage}

see \texttt{decoding.ipynb} Jupyter notebook for one session example
with different decoding procedures.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection{Preprocessing Data}\label{preprocessing-data}

The functions implemented here are designed to extract relevant
features, filter the data, and compile information that is essential for
applying decoding procedures on data.

\subsubsection{Overview}\label{overview}

The preprocessing workflow involves two main functions:

\begin{itemize}
\tightlist
\item
  \textbf{\texttt{pre\_processed\_active\_data()}}: Processes the active
  dataset.
\item
  \textbf{\texttt{pre\_processed\_passive\_data()}}: Processes the
  passive dataset.
\end{itemize}

Both functions aim to extract spiking data, filter it based on specific
conditions, and output firing rates, trial metadata, and channel
metadata.

\subsubsection{Preprocessing Steps}\label{preprocessing-steps}

\paragraph{1. Extract Trial
Information}\label{extract-trial-information}

\begin{itemize}
\tightlist
\item
  \textbf{Active Data}: Behavioral data is loaded using
  \texttt{get\_behavior()}. The trial information includes contrasts,
  trial onset times, and other metadata. The trials are filtered based
  on contrast levels (\texttt{contrast\_filter}) and probability left
  values (\texttt{probabilityLeft\_filter}). Each trial is labeled based
  on whether it contains right stimulus (\texttt{1}), left stimulus
  (\texttt{-1}), or no stimulus (\texttt{0}).
\item
  \textbf{Passive Data}: The passive dataset is loaded using the
  \texttt{passiveGabor} object from the \texttt{ONE} API. Trials are
  filtered based on contrast levels, and labels are assigned based on
  the visual field location of the stimulus (right or left).
\end{itemize}

\paragraph{2. Load and Filter Spiking
Data}\label{load-and-filter-spiking-data}

\begin{itemize}
\tightlist
\item
  Spiking data is loaded using \texttt{get\_spikes()}, and channel
  information is obtained using \texttt{get\_channels()}. Each cluster
  is assigned to a specific channel.
\item
  \textbf{Filtering}:

  \begin{itemize}
  \tightlist
  \item
    Clusters can be filtered to only include ``good'' clusters based on
    quality metrics (\texttt{only\_good\_clusters} parameter).
  \item
    Regions can be filtered using the \texttt{filter\_regions}
    parameter, which ensures that only specific brain regions are
    considered for the analysis.
  \end{itemize}
\end{itemize}

\paragraph{3. Calculate Firing Rates}\label{calculate-firing-rates}

\begin{itemize}
\tightlist
\item
  Firing rates are computed for each cluster using the
  \texttt{firingRate\_OnClusters()} function. This function bins spike
  times around each trial onset, and then normalizes firing rates by
  calculating z-scores relative to the baseline activity before stimulus
  onset.
\item
  The firing rates (\texttt{z\_score\_firing\_rate}) are computed
  separately for each trial and cluster, resulting in a tensor of shape
  \texttt{(n\_trials,\ n\_clusters,\ n\_time\_bins)}. The time bins are
  filtered to include only those after a specified minimum time
  (\texttt{min\_time}).
\end{itemize}

\paragraph{4. Extract Metadata}\label{extract-metadata}

\begin{itemize}
\tightlist
\item
  \textbf{Channel Metadata}: Information such as channel depth, atlas
  ID, coordinates (x, y, z), and acronyms are extracted for each
  selected channel and stored in a DataFrame (\texttt{channel\_info}).
\item
  \textbf{Trial Metadata}: Metadata such as trial indices, labels,
  contrasts, and distances to the latest block change are compiled into
  a DataFrame (\texttt{trial\_info}).
\end{itemize}

\paragraph{5. Output}\label{output}

The final preprocessed data for both active and passive datasets is
returned as a dictionary with the following keys: -
\textbf{\texttt{firing\_rates}}: Firing rate data for each channel,
stored as a dictionary where each key is a channel, and values are
z-scored firing rates for that channel. - \textbf{\texttt{trial\_info}}:
DataFrame containing trial-level metadata such as labels, contrasts, and
assigned side. - \textbf{\texttt{channel\_info}}: DataFrame containing
channel-level metadata such as coordinates and region acronyms. -
\textbf{\texttt{time\_bins}}: Array representing the time bins used for
calculating the firing rates.

\subsubsection{Key Parameters}\label{key-parameters-1}

\begin{itemize}
\tightlist
\item
  \textbf{\texttt{min\_contrast}}: Minimum contrast value used to filter
  the trials.
\item
  \textbf{\texttt{t\_bin}}: Size of the time bin (in seconds) used for
  calculating firing rates.
\item
  \textbf{\texttt{pre\_stim}} and \textbf{\texttt{post\_stim}}: Time (in
  seconds) before and after stimulus onset to consider when calculating
  firing rates.
\item
  \textbf{\texttt{filter\_regions}}: List of brain regions to include in
  the analysis.
\item
  \textbf{\texttt{only\_good\_clusters}}: Boolean flag indicating
  whether to filter clusters to include only those classified as
  ``good''.
\item
  \textbf{\texttt{contrast\_filter}} and
  \textbf{\texttt{probabilityLeft\_filter}}: Lists specifying valid
  contrast and probability left values for trial filtering.
\end{itemize}

\subsubsection{Usage}\label{usage-1}

\paragraph{Preprocessing Data}\label{preprocessing-data-1}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pre\_processed\_data }\OperatorTok{=}\NormalTok{ pre\_processed\_active\_data(eid, pid, min\_contrast}\OperatorTok{=}\FloatTok{0.25}\NormalTok{, t\_bin}\OperatorTok{=}\FloatTok{0.02}\NormalTok{, pre\_stim}\OperatorTok{=}\FloatTok{0.5}\NormalTok{, post\_stim}\OperatorTok{=}\FloatTok{1.0}\NormalTok{)}

\NormalTok{pre\_processed\_data }\OperatorTok{=}\NormalTok{ pre\_processed\_passive\_data(eid, pid, min\_contrast}\OperatorTok{=}\FloatTok{0.25}\NormalTok{, t\_bin}\OperatorTok{=}\FloatTok{0.02}\NormalTok{, pre\_stim}\OperatorTok{=}\FloatTok{0.5}\NormalTok{, post\_stim}\OperatorTok{=}\FloatTok{1.0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}




\end{document}
